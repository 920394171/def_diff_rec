{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "<h1> Deformation-Recovery Diffusion Model (DRDM):\n",
        "Instance Deformation for Image Manipulation and Synthesis\n",
        "</h1>\n",
        "\n",
        "<a href=\"https://jianqingzheng.github.io/def_diff_rec/\"><img alt=\"Website\" src=\"https://img.shields.io/website?url=https%3A%2F%2Fjianqingzheng.github.io%2Fdef_diff_rec%2F&up_message=online&up_color=darkcyan&down_message=offline&down_color=darkgray&label=Project%20Page\"></a>\n",
        "<a href=\"https://doi.org/10.48550/arXiv.2407.07295\"><img alt=\"Website\" src=\"https://img.shields.io/badge/arXiv-2407.07295-b31b1b.svg\"></a>\n",
        "<a href=\"https://github.com/jianqingzheng/def_diff_rec\"><img src=\"https://img.shields.io/github/stars/jianqingzheng/def_diff_rec?style=social&label=Code+★\" /></a>\n",
        "</div>\n",
        "\n",
        "\n",
        "Code for paper [Deformation-Recovery Diffusion Model (DRDM): Instance Deformation for Image Manipulation and Synthesis](https://doi.org/10.48550/arXiv.2407.07295)\n",
        "\n",
        "> This repo provides an implementation of the training and inference pipeline of DRDM based on Pytorch.\n",
        "\n"
      ],
      "metadata": {
        "id": "b6wz3wqFgL7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Contents ###\n",
        "- 1. Installation\n",
        "- 2. Usage\n",
        "  - 2.1. Setup\n",
        "  - 2.2. Training (~1 month)\n",
        "  - 2.3. Inference\n",
        "  - 2.4. Visualization\n",
        "- 3. Citing this work\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "V2D7wQZaIc4K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hO4x9NDrfGrm",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 1. Installation {run: \"auto\"}\n",
        "#@markdown Clone code from Github repo: https://github.com/jianqingzheng/def_diff_rec.git\n",
        "%cd /content\n",
        "\n",
        "!git clone https://github.com/jianqingzheng/def_diff_rec.git\n",
        "%cd def_diff_rec/\n",
        "\n",
        "#@markdown and Install packages\n",
        "\n",
        "import torch\n",
        "print('torch version: ',torch.__version__)\n",
        "\n",
        "!pip install pyquaternion==0.9.9\n",
        "!pip install pydicom==2.4.4\n",
        "#@markdown > `torch==1.12.1+cu113` was the version originally used, but has changed here due to Colab compatibility issues.\\\n",
        "#@markdown > Other versions of the packages could also be applicable."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "HyrqH26JxUyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Usage"
      ],
      "metadata": {
        "id": "Mm0FbA_17vTf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 2.1. Setup ###\n",
        "\n",
        "\n",
        "Directory layout:\n",
        "```\n",
        "[$DOWNLOAD_DIR]/def_diff_rec/\n",
        "├── Config/\n",
        "|   |   # configure file (.yaml files)\n",
        "|   └── config_[$data_name].yaml\n",
        "├── Data/\n",
        "|   ├── Src_data/[$data_name]/\n",
        "|   |   |   # processed image data for DRDM training (.nii|.nii.gz files)\n",
        "|   |   ├── 0001.nii.gz\n",
        "|   |   └── ...\n",
        "|   ├── Tgt_data/[$data_name]/\n",
        "|   |\t├── Tr/\n",
        "|   |   |   |   # image for deformation (.nii|.nii.gz files)\n",
        "|   |   |   ├── 0001.nii.gz\n",
        "|   |   |   └── ...\n",
        "|   |\t└── Gt/\n",
        "|   |       |   # label for deformation (.nii|.nii.gz files)\n",
        "|   |       ├── 0001.nii.gz\n",
        "|   |       └── ...\n",
        "|   └── Aug_data/[$data_name]/\n",
        "|       |   # augmented data will be export to here (.nii|.nii.gz files)\n",
        "|    \t├── img/\n",
        "|       |   |   # deformed image (.nii|.nii.gz files)\n",
        "|       |   ├── 0001.nii.gz\n",
        "|       |   └── ...\n",
        "|    \t├── msk/\n",
        "|       |   |   # deformed label (.nii|.nii.gz files)\n",
        "|       |   ├── 0001.nii.gz\n",
        "|       |   └── ...\n",
        "|    \t└── ddf/\n",
        "|           |   # deformation field (.nii|.nii.gz files)\n",
        "|           ├── 0001.nii.gz\n",
        "|           └── ...\n",
        "├── models/\n",
        "|   └── [$data_name]-[$model_name]/\n",
        "|       |   # the files of model parameters (.pth files)\n",
        "|       ├── [$epoch_id]_[$data_name]_[$model_name].pth\n",
        "|       └── ...\n",
        "└── ...\n",
        "```\n",
        "\n",
        "\n",
        "Configuration setting:\n",
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "| Argument              | Example           | Description                                \t|\n",
        "| --------------------- | ----------------- |----------------------------------------------|\n",
        "| `--data_name` \t    |'cmr', 'lct'        | The data folder name                    |\n",
        "| `--net_name` \t        |'recresacnet'      | The network name                    |\n",
        "| `--ndims` \t        |2, 3                | The dimension of image                    |\n",
        "| `--num_input_chn` \t|1, 3                | The channel number of input image               |\n",
        "| `--img_size` \t        |256, 128            | The size of image                    |\n",
        "| `--timesteps` \t    |80                 | The time step number for deformation             |\n",
        "| `--v_scale` \t        |4.0e-05             | The time step number for deformation             |\n",
        "| `--batchsize` \t    |64, 4               | The batch size for training                    |\n",
        "| `--ddf_pad_mode` \t    |'border', 'zeros'   | The padding mode for integrating deformation field   |\n",
        "| `--img_pad_mode` \t    |'border', 'zeros'   | The padding mode for resampling image    |\n",
        "| `--resample_mode` \t|'nearest', 'bicubic'| The interpolation mode for resampling image     |\n",
        "| `--device` \t        |'cuda', 'cpu'       | The used device     |\n",
        "| `--patients_list` \t|[], [1], [1,2]       | The selected list of subject for augmentation     |\n",
        "</div>\n",
        "\n",
        "> configuration settings are edited in `[$DOWNLOAD_DIR]/def_diff_rec/Config/*.yaml`\n"
      ],
      "metadata": {
        "id": "muTruGCpicYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "nc6irIRCxSEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. Training (~1 month) ###\n",
        "\n",
        "1. Run ```python DRDM_train.py --config Config/config_$data_name.yaml```\n",
        "2. Check the saved model in `/content/def_diff_rec/models`\n"
      ],
      "metadata": {
        "id": "ECD58BA9iV2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown \\* Example for training (default):\n",
        "data_name = 'cmr' #@param [\"cmr\",\"lct\"]\n",
        "\n",
        "!python DRDM_train.py --config Config/config_{data_name}.yaml\n",
        "\n",
        "#@markdown > Training from scratch would take around 1 month,\n",
        "#@markdown > which may not be possible in this demo\n",
        "#@markdown > (the usage time limit in Colab is <12/24 hours).\n"
      ],
      "metadata": {
        "id": "gUvY0DiSi-RD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "HH7rcmijxQmV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3. Augmentation ###\n",
        "1. Put the data to augment in `/content/def_diff_rec/Data/Tgt_data`\n",
        "2. Run ```python DRDM_augment.py --config Config/config_$data_name.yaml```\n",
        "3. Check the output data in `/content/def_diff_rec/Data/Aug_data`"
      ],
      "metadata": {
        "id": "s5JFReKFDyPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown \\* Example for augmentation (default):\n",
        "data_name = 'cmr' #@param [\"cmr\",\"lct\"]\n",
        "\n",
        "!python DRDM_augment.py --config Config/config_{data_name}.yaml\n",
        "\n",
        "#@markdown > default model is 0000.pth."
      ],
      "metadata": {
        "id": "Av3PcKSNFMxv",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown \\* Download the result file (after inference) from `/content/def_diff_rec/Data/Aug_data/$data_name`.\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "download_path = os.path.join('Data','Aug_data',data_name)\n",
        "\n",
        "!zip -r results.zip {download_path}/*\n",
        "files.download(f\"results.zip\")\n",
        "# files.download(download_path)\n",
        "print('Download the results from: '+download_path)"
      ],
      "metadata": {
        "id": "XcIc7RaABHDD",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "YAXj7i_ZxMdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.4 Visualization\n",
        "data_type = 'Aug_data' #@param [\"Aug_data\",\"Tgt_data\",\"Src_data\"]\n",
        "data_format = 'img' #@param {type:\"string\"}\n",
        "selected_img = 'Patient0001_Slice000000_AugImg0000_NoiseStep0048.nii.gz' #@param {type:\"string\"}\n",
        "\n",
        "img_path = os.path.join('Data',data_type,data_name,data_format,selected_img)\n",
        "\n",
        "\n",
        "from os.path import dirname, join\n",
        "from pprint import pprint\n",
        "import numpy as np\n",
        "import ipywidgets as ipyw\n",
        "import matplotlib.pyplot as plt\n",
        "import nibabel as nib\n",
        "class ImageSliceViewer3D:\n",
        "  \"\"\"\n",
        "  ImageSliceViewer3D is for viewing volumetric image slices in jupyter or\n",
        "  ipython notebooks.\n",
        "\n",
        "  User can interactively change the slice plane selection for the image and\n",
        "  the slice plane being viewed.\n",
        "Arguments:\n",
        "  Volume = 3D input image\n",
        "  figsize = default(8,8), to set the size of the figure\n",
        "  cmap = default('gray'), string for the matplotlib colormap. You can find\n",
        "  more matplotlib colormaps on the following link:\n",
        "  https://matplotlib.org/users/colormaps.html\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, volume, figsize=(100,100), cmap='gray'):\n",
        "    self.volume = volume\n",
        "    self.figsize = figsize\n",
        "    self.cmap = cmap\n",
        "    self.v = [np.min(volume), np.max(volume)]\n",
        "\n",
        "    # Call to select slice plane\n",
        "    ipyw.interact(self.views)\n",
        "\n",
        "  def views(self):\n",
        "    self.vol1 = np.transpose(self.volume, [1,2,0])\n",
        "    self.vol2 = np.rot90(np.transpose(self.volume, [2,0,1]), 3) #rotate 270 degrees\n",
        "    self.vol3 = np.transpose(self.volume, [0,1,2])\n",
        "    maxZ1 = self.vol1.shape[2] - 1\n",
        "    maxZ2 = self.vol2.shape[2] - 1\n",
        "    maxZ3 = self.vol3.shape[2] - 1\n",
        "    ipyw.interact(self.plot_slice,\n",
        "        z1=ipyw.IntSlider(min=0, max=maxZ1, step=1, continuous_update=False,\n",
        "        description='Axial:'),\n",
        "        z2=ipyw.IntSlider(min=0, max=maxZ2, step=1, continuous_update=False,\n",
        "        description='Coronal:'),\n",
        "        z3=ipyw.IntSlider(min=0, max=maxZ3, step=1, continuous_update=False,\n",
        "        description='Sagittal:'))\n",
        "  def plot_slice(self, z1, z2, z3):\n",
        "    # Plot slice for the given plane and slice\n",
        "    f,ax = plt.subplots(1,3, figsize=self.figsize)\n",
        "    #print(self.figsize)\n",
        "    #self.fig = plt.figure(figsize=self.figsize)\n",
        "    #f(figsize = self.figsize)\n",
        "    ax[0].imshow(self.vol1[:,:,z1], cmap=plt.get_cmap(self.cmap),\n",
        "        vmin=self.v[0], vmax=self.v[1])\n",
        "    ax[1].imshow(self.vol2[:,:,z2], cmap=plt.get_cmap(self.cmap),\n",
        "        vmin=self.v[0], vmax=self.v[1])\n",
        "    ax[2].imshow(self.vol3[:,:,z3], cmap=plt.get_cmap(self.cmap),\n",
        "        vmin=self.v[0], vmax=self.v[1])\n",
        "    plt.show()\n",
        "\n",
        "ImageSliceViewer3D(nib.load(img_path).slicer[:,:,:].get_fdata())\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jvoXdfGZvJFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "EtbePvYAxOjF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Citing this work\n",
        "\n",
        "Any publication that discloses findings arising from using this source code or the network model should cite:\n",
        "\n",
        "```bibtex\n",
        "@article{zheng2024deformation,\n",
        "  title={Deformation-Recovery Diffusion Model (DRDM): Instance Deformation for Image Manipulation and Synthesis},\n",
        "  author={Zheng, Jian-Qing and Mo, Yuanhan and Sun, Yang and Li, Jiahua and Wu, Fuping and Wang, Ziyang and Vincent, Tonia and Papie{\\.z}, Bart{\\l}omiej W},\n",
        "  journal={arXiv preprint arXiv:2407.07295},\n",
        "  doi = {https://doi.org/10.48550/arXiv.2407.07295},\n",
        "  url = {https://doi.org/10.48550/arXiv.2407.07295},\n",
        "  keywords = {Image Synthesis, Generative Model, Data Augmentation, Segmentation, Registration}\n",
        "  year={2024}\n",
        "}     \n",
        "```\n"
      ],
      "metadata": {
        "id": "Dg0PMCfSwcXx"
      }
    }
  ]
}